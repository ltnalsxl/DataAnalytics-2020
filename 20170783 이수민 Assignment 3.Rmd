---
title: "Assignment#3"
subtitle: "Data Analysis and its Applications"
author: "20170783 이수민"
date: '2020 4 26 '
output: html_document
---

```{r, message = FALSE}
library(ggplot2)
library(corrplot)
library(readr)
library(GGally)
library(psych)
library(rsample)
library(vip)
library(caret)
library(leaps)
library(glmnet)
library(ISLR)
library(rsample)
```

## 1. Climate Change data file을 이용한 Linear Regression

**ClimateChange.csv 파일**은 1983년 5월부터 2008년 12월까지의 지구의 평균적인 대기 질 및 기후 관련 데이터를 포함한다. 변수에 대한 상세한 설명을 아래와 같다. 이를 활용하여 세계의 평균 기온을 예측하기 위한 모델을 만
들어 보고자 한다. Temp 변수를 target으로, Year 및 Month를 제외한 나머지 8개의 변수를 feature로 사용하자.

- Year : 관측 년도
- Month : 관측 월
- Temp : 세계 평균 기온 (기준값 대비 차이)
- CFC.11 : 대기 중 CFC-11 프레온가스 농도 (단위: ppbv)
- CFC.12 : 대기 중 CFC-12 프레온가스 농도 (단위: ppbv)
- CO2 : 대기 중 이산화탄소 농도 (단위: ppmv)
- N2O : 대기 중 아산화질소 농도 (단위: ppmv)
- CH4 : 대기 중 메탄 농도 (단위: ppmv)
- Aerosols : The mean stratospheric aerosol optical depth - 성층권 에어로졸 깊이
- TSI : The total solar irradiance - 대기 중 단위 면적당 태양에너지
- MEI : Multivariate El Nino Southern Oscillation index - 태평양에서의 기후 효과의 강도에 대한 척도

data 불러들이기 (readr package 사용)
```{r, message = FALSE}
climate <- read_csv('ClimateChange.csv')
```
```{r}
str(climate)
```

### 문제 1
**Year 및 Month를 제외한 9개의 변수들 간의 상관 관계를 다양한 그래프를 활용하여 시각화해보고, 이로부터 데이터의 특성을 분석해보자.**

변수들 간의 상관관계는 다양한 package를 이용하여 나타낼 수 있다.

```{r, warnings = FALSE, message = FALSE}
ggpairs(climate[c(3:11)])
pairs.panels(climate[c(3:11)])
pairs(cor(climate[c(3:11)]))
```

**하지만 변수의 개수가 너무 많을 때는 위와 같은 방법으로 시각화를 해서 직관적인 결과를 얻을 수 없다.** corrplot() function을 사용하여 climate data의 feature들과 target변수와의 관계를 조금 더 직관적으로 나타내보았다.

```{r}
climate_cor <- cor(climate[c(3:11)])
corrplot(climate_cor, method="number")
corrplot(climate_cor, method='shade', shade.col=NA, tl.col='black', tl.srt=45)
```

1 또는 -1에 가까울 수록 두 변수간의 상관관계가 있다는 것인데, 두 변수의 상관계수가 -1 또는 1에 가까울수록 더 짙은 붉은색 혹은 파란색으로 나타나다는 것을 알 수 있다. 시각화를 진행한 그래프들 중에서 위 그래프가 가장 변수들 간의 상관관계를 잘 나타낸다고 생각한다.

Temp (target feature) 변수와 다른 feature들간의 상관관계를 살펴보면, CO2, N2O, CFC.12가 비교적 높은 상관관계를 보인다는 것을 알 수 있다. 하지만 단순히 상관관계가 높다는 것이 parameter tuning의 단독적인 지표로 쓰일 수는 없다.



### 문제 2
**2004년 이후의 데이터를 test set으로 2003년까지의 데이터를 training set으로 분할하자. 그리고 training set을 활용하여 linear regression model을 수립하자. 이때 8개의 feature변수를 모두 포함시킨다.**

우선 2004년 이후의 데이터를 test set으로 2003년까지의 데이터를 training set으로 분할하는 Data Splitting 과정을 진행한다. 이 경우에는 Year을 정해주었기 때문에 Stratified sampling을 사용하지 않고 직접 train set과 test set을 분리해주었다.
```{r}
climate_train <- climate[1:248,3:11]
climate_test <- climate[249:308,3:11]
```

train set과 test set 분리를 진행한 후, target 변수의 비율이 일정하게 들어가있는지를 보기 위한 plot을 그린다.
```{r}
ggplot(climate_train, aes(x=Temp)) + geom_density(color="magenta4") +
geom_density(data=climate_test, aes(x=Temp), color="turquoise4") +
theme_bw()
```

시각화 결과를 살펴보면, 단순히 Year을 기준으로 train과 test set을 split 했기 때문에 Target 변수의 비율이 일정하게 들어가있지 않은 것을 확인할 수 있다.

training set을 활용하여 linear regression model을 수립한다.

```{r}
model1 <- lm(Temp~., data=climate_train)
summary(model1)
```
R-squared 값이 각각 0.7133, 0.7037인 것으로 보아 이 모델은 약 70%의 설명력을 가진다고 볼 수 있다. 하지만 r-squared 값은 독립변수의 수가 증가할수록 무조건 높아지기 때문에, r-squared 값이 높다고 해서 예측 성능이 높은 것을 의미하지는 않는다. feature의 개수가 증가하면 모델이 복잡해지게 되어 variance가 높아지기 때문이다.

#### **2-a.** 
어떠한 feature들이 Temp에 큰 영향을 미치는가?

어떠한 feature들이 Temp에 큰 영향을 미치는지 파악하기 위해서는 vip() function을 이용하여 model1에 속한 feature들을 중요도 순서로 시각화하는 방법이 있다.
```{r}
vip(model1)
```

시각화를 통해 Target변수에 영향을 미치는 정도를 분석한 결과, MEI(태평양에서의 기후 효과의 강도), Aerosols(성층권 에어로졸 깊이), TSI(대기 중 단위 면적당 태양에너지) 순으로 Temp(세계 평균 기온)에 영향을 많이 미친다는 것을 파악할 수 있다.

#### **2-b.**
N2O와 CFC-11은 지구의 지표면에서 우주로 발산하는 적외선 복사열을 흡수하여 지구 표면의 온도를 상승시키
는 역할을 하는 온실가스로 알려져 있다. 모델에서 N2O와 CFC-11 변수의 coefficient는 양수 값을 가지는가?
음수 값을 가지는가? 만약 음수값을 가진다면 N2O와 CFC-11의 양이 증가할수록 평균 기온이 감소한다는 것을
의미하므로 일반적인 지식과 모순된다. 이러한 모순된 결과가 도출되는 원인은 무엇일까?

```{r}
ggplot(climate_train, aes(x = N2O, y = Temp)) + geom_point(alpha = 0.5) + geom_smooth(method = "lm", se = FALSE) + theme_bw()
```


linear regression 분석 시 coefficient (회귀계수) 값은, feature가 target variable에 어떠한 영향을 주는지 나타내는 지표이다.
N2O feature의 회귀계수 추정치가 -2.525e-02인 것으로 보아, 이는 feature가 1 증가할 때, target variable은 약 -0.02525 정도 증가시키는 영향을 준다는 것을 의미한다.
즉 N2O , CFC.11은 음수 coefficient값을 가지므로, feature값이 증가할수록 target variable은 감소하게 되는데, N2O와 CFC-11의 양이 증가할수록 평균 기온이 증가한다는 일반적인 지식과 모순된다. 

이런 모순된 결과가 발생하는 원인은 과적합(overfitting)이라고 생각한다. 모델을 학습할 때 설명변수(feature)의 개수가 지나치게 많을 경우 overfitting이 발생할 수 있다. overfitting이 발생하게 되면 model의 variace가 높아져 결과가 모순될 수 있다.


### 문제 3
**3. MEI, TSI, Aerosols, N2O 4개의 feature만 사용하여 regression model을 만들어 보자.**
```{r}
model2 <- lm(Temp ~ MEI + TSI + Aerosols + N2O, climate_train)
summary(model2)
```

#### 3-a.
N2O 변수의 coefficient를 2번 모델과 비교해 보자.

model2의 N2O 변수의 coefficient 값은 2.524e-02으로, model1에서 나왔던 결과와 부호가 다르게 정상적인 양수 값이 도출되었다.

변수의 개수가 줄어듦에 따라 과적합 발생 문제가 해결되었음을 알 수 있다.

#### 3-b.
두 모델의 R2값, Adusted R2값, test set error (test set에 대한 RMSE) 를 비교해 보자. 어떤 모델을 선택
하겠는가?

1) 두 모델의 R-squared값 비교

```{r}
model1_summary <- summary(model1)
model1_summary$r.squared
```

```{r}
model2_summary <- summary(model2)
model2_summary$r.squared
```

model1의 r-squared 값은 0.713274, model2의 r-squared 값은 0.6799437이다. 
즉, model1의 feature들은 target 변수에 대해 약 71%의 설명력을 가지며, model2의 feature들은 target 변수에 대해 약 67%의 설명력을 가진다. 하지만 r-squared값은 변수의 개수가 많을수록 올라가는 지표이기 때문에 이 두 모델을 비교하기에 적절하지 않다.

이에 변수의 개수가 많아질수록 penalty를 부여해 r-squared값을 줄인 adjusted r-squared값으로 두 모델을 비교한다.

2) 두 모델의 R-squared값 비교
```{r}
model1_summary <- summary(model1)
model1_summary$adj.r.squared
model2_summary <- summary(model2)
model2_summary$adj.r.squared
```
adjusted r-squared값을 비교한 결과, model1은 0.7036765, model2는 0.6746752 라는 결과가 나왔다.
model1이 model2보다 종속변수를 더 잘 설명한다고 볼 수 있다.

3) test set erorr(test set에 대한 RMSE) 값을 계산하여 비교해본다.
```{r}
climate_test_pred_model1 <- predict(model1, climate_test)
sqrt(mean((climate_test_pred_model1- climate_test$Temp)^2))
```

```{r}
climate_test_pred_model2 <- predict(model2, climate_test)
sqrt(mean((climate_test_pred_model2 - climate_test$Temp)^2))
```

test set error값이 model2에서 더 높게 나타난다.

**두 모델의 r-squared, adjusted r-squared, test set error 3가지 지표를 종합적으로 고려해보았을 때, model1을 선택하는 것이 적절하다.**



### 문제 4
**8개의 feature를 대상으로 cross validation을 활용한 stepwise variable selection을 수행해보자.**

#### 4-a.
Forward selection과 backward selection의 결과를 비교해보자.

```{r}
reg_fwd <- regsubsets(Temp~., data = climate_train, nvmax = 8, method ="forward")
reg_bwd <- regsubsets(Temp~., data = climate_train, nvmax = 8, method = "backward")
reg_fwd_summary <- summary(reg_fwd)
reg_bwd_summary <- summary(reg_bwd)

max(reg_fwd_summary$adjr2)
which.max(reg_fwd_summary$adjr2)

max(reg_bwd_summary$adjr2)
which.max(reg_bwd_summary$adjr2)
```

get regression coefficient of the best model
```{r}
coef_fwd <- coef(reg_fwd, which.max(reg_fwd_summary$adjr2))
coef_bwd <- coef(reg_bwd, which.max(reg_bwd_summary$adjr2))

coef_fwd
coef_bwd
```

get matrix consisting of only feature variables
```{r}
test.mat <- model.matrix(Temp~., data = climate_test)
```

compute predicted temp for test set
```{r}
test_pred_fwd <- test.mat[,names(coef_fwd)] %*% coef_fwd
RMSE(test_pred_fwd, climate_test$Temp)

test_pred_bwd <- test.mat[,names(coef_bwd)] %*% coef_bwd
RMSE(test_pred_bwd, climate_test$Temp)
```

Forward stepwise selection와 backward stepwise selection의 결과 7개의 feature가 선택되었다.
이때 RMSE 값은 0.08359067으로 도출되었다.

Cross Validation을 수행하여 stepwise selection 진행


먼저 Forward stepwise selection을 진행한다.

```{r}
train.control <- trainControl(method = "repeatedcv", number = 10, repeats = 10)
set.seed(2020)
fwd_model <- train(Temp ~., data = climate_train, method = "leapForward", tuneGrid = data.frame(nvmax = 1:8), trControl = train.control)

fwd_model$results
fwd_model$results

ggplot(fwd_model$results, aes(x = nvmax, y = RMSE)) + geom_point() + geom_line() + theme_bw()
coef_fwd_cv <- coef(fwd_model$finalModel, fwd_model$bestTune$nvmax)
test_pred_fwd_cv <- test.mat[, names(coef_fwd_cv)] %*% coef_fwd_cv
RMSE(test_pred_fwd_cv, climate_test$Temp)
```
7개의 변수가 포함되었을 때 model의 cross-validated RMSE 값이 가장 작은 것을 알 수 있다. 이 model의 RMSE값은 0.08359067으로 계산되었다.

다음으로 Backward Stepwise Selection 수행
```{r}
train.control <- trainControl(method = "repeatedcv", number = 10, repeats = 10)
set.seed(2020)
bwd_model <- train(Temp ~., data = climate_train, method = "leapBackward", tuneGrid = data.frame(nvmax = 1:8), trControl = train.control)

bwd_model$results
bwd_model$results

ggplot(bwd_model$results, aes(x = nvmax, y = RMSE)) + geom_point() + geom_line() + theme_bw()
coef_bwd_cv <- coef(bwd_model$finalModel, bwd_model$bestTune$nvmax)
test_pred_bwd_cv <- test.mat[, names(coef_bwd_cv)] %*% coef_bwd_cv
RMSE(test_pred_bwd_cv, climate_test$Temp)
```
backward selection도 forward selection과 같은 결과를 도출한 것을 확인할 수 있다.

#### 4-b.
Prediction accuracy와 Model interpretability를 종합적으로 고려하여 best 모델을 하나 결정하자.

Cross validation을 이용한 parameter tuning을 통해 best nvmax = 7임을 찾아냈다. 마지막으로 best모델을 선정하기 위해 training set과 test set을 모두 포함하는 전체 dataset에 대해서 다시 stepwise selection을 적용하여 최종 model을 만든다.
```{r}
reg_fwd_best <- regsubsets(Temp~., data = climate[3:11], nvmax = 8, method = "forward")
coef_fwd_best <- coef(reg_fwd_best, 7)
coef_fwd_best
```

이떄 RMSE값은 다음과 같이 계산할 수 있다.
```{r}
test_pred_fwd_best_cv <- test.mat[, names(coef_fwd_best)] %*% coef_fwd_best
RMSE(test_pred_fwd_best_cv, climate_test$Temp)
```

RMSE값은  0.0773725으로, 앞에서 계산한 RMSE값과 차이가 나는 것을 볼 수 있다. (coefficient값도 마찬가지)

+추가

그래프를 보면 nvmax가 4일때 RMSE값이 소폭 감소한 것을 확인할 수 있다. 최소한의 변수 개수로 최대의 성능을 내기 위해서는 변수의 개수를 4로 선정하는 것도 차선의 선택이 될 수 있다.

```{r}
coef_fwd_best4 <- coef(reg_fwd_best, 4)
coef_fwd_best4
test_pred_fwd_best_cv4 <- test.mat[,names(coef_fwd_best4)] %*% coef_fwd_best4
RMSE(test_pred_fwd_best_cv4, climate_test$Temp)
```

### 문제 5
**Prediction accuracy를 높이기 위해, 기존 8개의 feature들 외에 feature들 사이의 모든 interaction effect, 그리고 CO2, CFC.11, CFC.12의 제곱항들을 모두 추가한 모델을 대상으로 cross validation을 활용한 stepwise variable selection을 수행해보자.**

#### 5-a.
Forward selection과 backward selection의 결과를 비교해보자.

```{r}
reg_fwd5 <- regsubsets(Temp~(.)^2 + I(CO2^2) + I(CFC.11^2) +I(CFC.12^2), data = climate_train, nvmax = 40, method ="forward")
reg_bwd5 <- regsubsets(Temp~(.)^2 + I(CO2^2) + I(CFC.11^2) +I(CFC.12^2), data = climate_train, nvmax = 40, method = "backward")
reg_fwd_summary5 <- summary(reg_fwd5)
reg_bwd_summary5 <- summary(reg_bwd5)

max(reg_fwd_summary5$adjr2)
which.max(reg_fwd_summary5$adjr2)

max(reg_bwd_summary5$adjr2)
which.max(reg_bwd_summary5$adjr2)
```


```{r}
coef_fwd5 <- coef(reg_fwd5, which.max(reg_fwd_summary5$adjr2))
coef_bwd5 <- coef(reg_bwd5, which.max(reg_bwd_summary5$adjr2))

coef_fwd5
coef_bwd5
```

```{r}
test.mat5 <- model.matrix(Temp~(.)^2 + I(CO2^2) + I(CFC.11^2) +I(CFC.12^2), data = climate_test)
test_pred_fwd5 <- test.mat5[,names(coef_fwd5)] %*% coef_fwd5
RMSE(test_pred_fwd5, climate_test$Temp)
```
```{r}
test_pred_bwd5 <- test.mat5[,names(coef_bwd5)] %*% coef_bwd5
RMSE(test_pred_bwd5, climate_test$Temp)
```


#### 5-b.
Cross validated RMSE가 가장 낮은 best 모델을 결정하자. 어떠한 변수들이 best 모델에 포함되는가?

Cross Validation을 수행하여 stepwise selection 진행한다.
```{r}
train.control <- trainControl(method = "repeatedcv", number = 10, repeats = 10)
set.seed(2020)
fwd_model5 <- train(Temp~(.)^2 + I(CO2^2) + I(CFC.11^2) +I(CFC.12^2), data = climate_train, method = "leapForward", tuneGrid = data.frame(nvmax = 1:40), trControl = train.control)

fwd_model5$results
ggplot(fwd_model5$results, aes(x = nvmax, y = RMSE)) + geom_point() + geom_line() + theme_bw()
coef_fwd_cv5 <- coef(fwd_model5$finalModel, fwd_model5$bestTune$nvmax)
test_pred_fwd_cv5 <- test.mat5[, names(coef_fwd_cv5)] %*% coef_fwd_cv5
RMSE(test_pred_fwd_cv5, climate_test$Temp)
```

13개의 변수가 포함되었을 때 model의 cross-validated RMSE 값이 가장 작은 것을 알 수 있다. 이 model의 cross-validated RMSE값은 0.09242062으로 계산되었다.

다음으로 Backward Stepwise Selection 수행
```{r}
train.control <- trainControl(method = "repeatedcv", number = 10, repeats = 10)
set.seed(2020)
bwd_model5 <- train(Temp~(.)^2 + I(CO2^2) + I(CFC.11^2) +I(CFC.12^2), data = climate_train, method = "leapBackward", tuneGrid = data.frame(nvmax = 1:40), trControl = train.control)

bwd_model5$results
ggplot(bwd_model5$results, aes(x = nvmax, y = RMSE)) + geom_point() + geom_line() + theme_bw()
coef_bwd_cv5 <- coef(bwd_model5$finalModel, bwd_model5$bestTune$nvmax)
test_pred_bwd_cv5 <- test.mat5[, names(coef_bwd_cv5)] %*% coef_bwd_cv5
RMSE(test_pred_bwd_cv5, climate_test$Temp)
```

backward selection도 forward selection과 같이 변수가 13개 포함되어있을 때 RMSE값이 최소이다. 이 모델의 Cross-validated RMSE 값은 0.2465357이다.
Cross Validation을 이용하여 parameter tuning을 진행한 결과 best nvmax값이 13이라는 것을 찾았다. Forward selection에서 13개의 변수가 포함되어있을 떄 Cross-validated RMSE 값이 0.09242062로 최소이다.마지막으로 training set과 test set을 모두 포함하는 전체 dataset인 climate data에 대해서 다시 stewise selection을 적용하여 최종적으로 RMSE가 가장 낮은 best 모델을 결정한다.

```{r}
reg_fwd_best5 <- regsubsets(Temp~(.)^2 + I(CO2^2) + I(CFC.11^2) +I(CFC.12^2), data = climate[3:11], nvmax = 40, method = "forward")
coef_fwd_best5 <- coef(reg_fwd_best5, 13)
coef_fwd_best5
```
Cross validated RMSE가 0.07834731으로 가장 낮은 best 모델은 feature은 위와 같다. 
다음과 같은 변수들이 best 모델에 포함된다.

 MEI, TSI, MEI:CO2, MEI:CFC.11, CO2:CH4, CO2:N2O, CO2:CFC.12, CO2:Aerosols, CH4:CFC.11, CH4:Aerosols, CFC.11:CFC.12, CFC.11:Aerosols,  CFC.12:Aerosols 
 
 이때의 Cross Validated RMSE값은 0.07834731으로, 다음과 같이 구할 수 있다. 
```{r}
test_pred_fwd_best_cv5 <- test.mat5[, names(coef_fwd_best5)] %*% coef_fwd_best5
RMSE(test_pred_fwd_best_cv5, climate_test$Temp)
```
 
 
 
### 문제 6
**2, 3, 4, 5번에서 수립된 4개의 모델에 대해서 test set (2004년 이후 데이터)에 대한 prediction accuracy (RMSE) 를 비교해 보자. 예상한 대로 결과가 나오는가? 그렇지 않다면 그 원인은 무엇일지 분석해보자.**


```{r}
RMSE_model1 <- sqrt(mean((climate_test_pred_model1- climate_test$Temp)^2))
RMSE_model2 <- sqrt(mean((climate_test_pred_model2 - climate_test$Temp)^2))
RMSE_model3 <- RMSE(test_pred_fwd_best_cv, climate_test$Temp)
RMSE_model4 <- RMSE(test_pred_fwd_best_cv5, climate_test$Temp)

RMSE_model1; RMSE_model2; RMSE_model3; RMSE_model4
```

첫번째 모델: 8개의 feature변수를 모두 포함시킨 linear regression model
두번째 모델: MEI, TSI, Aerosols, N2O 4개의 feature만 사용한 regression model
세번째 모델: 8개의 feature를 대상으로 cross validation을 활용한 stepwise variable selection을 수행한 best model
네번째 모델: 기존 8개의 feature들 외에 feature들 사이의 모든 interactioneffect, 그리고 CO2, CFC.11, CFC.12의 제곱항들을 모두 추가하여 cross validation을 활용한 stepwise variable selection을 수행한 model

8개의 feature를 대상으로 cross validation을 활용한 stepwise variable selection을 수행한 best model의 RMSE 값이 가장 작은 것을 알 수 있다.

Test값의 RMSE 값이 예상한대로 결과가 나오지 않는 이유는 앞서 아래와 같은 그래프로 확인했듯, stratified sampling을 진행하지 않았기 때문에 test set과 train set의 target 변수 비율이 일정하지 않기 때문이다.
```{r}
ggplot(climate_train, aes(x=Temp)) + geom_density(color="magenta4") +
geom_density(data=climate_test, aes(x=Temp), color="turquoise4") +
theme_bw()
```





## 2. Regression on Simulated Data 
rnorm() 함수를 활용해서 표준정규분포로부터 길이가 100인 feature vector 를 생성하고, 평균이 0, 표준편차가 3인 정규분포로부터 길이가 100인 오차 vector 을 생성한다.

```{r}
set.seed(20)
X <- rnorm(100)
set.seed(40)
eps <- rnorm(100,0,3)
```


길이가 100인 target vector Y를 다음 식을 사용하여 생성한다.

**Y = 1 + 2X + 3X2 + 4X3 + ϵ**


실제 regression coefficient β0 = 1 β1 = 2 β2 = 3 β3 = 4 과 같고, 이를 추정하기 위한 linear regression model을 만들어보자. 
```{r}
b1 <- 1
b2 <- 2
b3 <- 3
b4 <- 4
Y <- b1 + b2*X + b3*X^2 + b4*X^3 + eps
```

### 문제 1. 
**X, X2, X3…, X10 의 10개 변수를 feature로, 를 target으로 설정하자. 이때 feature 변수들과 target 변수 사이의 상관관계를 시각화해보자.**

```{r}
data <- as.data.frame(cbind(Y,X,X^2,X^3,X^4,X^5,X^6,X^7,X^8,X^9,X^10))
names(data) <- c("Y","X1","X2","X3","X4","X5","X6","X7","X8","X9","X10")
str(data)
```
```{r}
cor <- cor(data)
corrplot(cor, method='shade', shade.col=NA, tl.col='black', tl.srt=45)
```

그래프를 보면, X1, X3, X5, X7, X9 (양의 상관간계)는 제곱이 될수록 Y와의 상관관계 정도가 옅어진다 (낮아진다).
반면 X2, X4, X6, x8, x10 (음의 상관관계) 같은 경우에는 제곱이 될수록 그래프의 색이 짙어지는 것으로 보아, 상관관계 정도가 높아짐을 알 수 있다. 
### 문제 2.
**10개의 feature를 모두 포함하는 linear regression model을 만들어보자.**

7:3의 비율로 train set 과 test set을 split한다. train, test set에서의 target 변수 비율을 맞추기 위해 stratified sampling을 진행한다.

```{r}
set.seed(2020)
split <- initial_split(data,prop = 0.7, strata = "Y")
data_train <- training(split)
data_test <- testing(split)
ggplot(data_train, aes(x=Y)) + geom_density(color="magenta4") +
geom_density(data=data_test, aes(x=Y), color="turquoise4") +
theme_bw()
```

train set과 test set에서 target 변수인 Y의 비율이 거의 일정하게 나타남을 확인할 수 있다.
```{r}
model_data1 <- lm(Y~., data = data_train)
model_data1
summary(model_data1)
```
```{r}
vip(model_data1)
```

통계적으로 눈에 띄는 변수는 없지만, Importance plot을 통해 X1이 가장 큰 영향을 끼치는 변수라는 것을 알 수 있다. 

regression coefficient 값을 살펴보면, 
추정된 값: β0 = 1.1601 β1 = 3.1671 β2 = 1.4574 β3 = 5.7567
실제 값: β0 = 1 β1 = 2 β2 = 3 β3 = 4

어느정도 오차를 보인다.

### 문제 3. 
**X, X2, X3의 3개 변수를 feature로, Y를 target으로 linear regression model을 만들어보자. 모든 feature들이 통계적으로 유의한가? regression coefficient βĵ값을 실제 βj 값과 비교해보자.**

```{r}
ggplot(data[1:4], aes(x=Y)) + geom_density(color = "red")
set.seed(2020)
split <- initial_split(data[1:4],prop = 0.7, strata = "Y")
data_train3 <- training(split)
data_test3 <- testing(split)
ggplot(data_train3, aes(x=Y)) + geom_density(color="magenta4") +
geom_density(data=data_test3, aes(x=Y), color="turquoise4") +
theme_bw()
```

```{r}
model_data2 <- lm(Y~., data = data_train3)
model_data2
summary(model_data2)
```

### 문제 4.

**X, X2, X3…, X10의 10개 변수를 feature로, 를 target으로 Lasso regression model을 만들어본다. Cross validation으로 최적의 모델을 찾아보자. 이 모델에는 어떤 변수가 포함되었는가? regression coefficient 값을 실제 값과 비교해보자. 그리고 결과를 바탕으로 Lasso regression의 효과에 대해서 설명해보자.**

```{r}
X <- model.matrix(Y ~., data_train)[,-1]
Y <- data_train$Y
```

glmnet() function 의 alpha 옵션을 1로 설정하여 lasso regression을 수행

```{r}
lasso <- glmnet(x = X, y = Y, alpha = 1)
plot(lasso, xvar= "lambda")
```

lambda가 커질수록 0이 되는 regression coefficient의 수가 늘어나고, model에 포함된 feature의 개수도 같이 감소한다.

cv.glmnet() function을 사용하여 lambda에 대한 cross validation을 수행한다.

Lasso regression에 대해 CV를 수행해보자.
```{r}
set.seed(2020)
cv_lasso <- cv.glmnet(x = X, y = Y, alpha = 1, nfolds = 10)
plot(cv_lasso)
```

lambda의 변화에 따른 cross validated MSE의 변화를 보여주는 그래프이다. 그래프에서 점선 구간은 MSE
가 가장 작은 lambda 의 주변 구간을 의미한다. 이 경우 cross-validated error가 최소인 구간에 대한 model에
속하는 feature의 수는 9-10개 정도로 줄어든다.

**best lambda 값을 찾고 best lambda 값을 가지는 lasso regression model을 찾자.**

cross validation을 이용해 최적의 model을 찾는다.

1) best lambda값을 찾고 best 값을 가지는 ridge regression model과 lasso regression model에 대한 test set error (RMSE)를 계산하는 방법

우선 lasso regression에서 MSE를 가장 작게 하는 best lambda 값을 찾는다.
```{r}
best_lambda_lasso <- cv_lasso$lambda.min
best_lambda_lasso
```

test dataset에 대해 best lambda model의 성능을 평가
```{r}
testX <- model.matrix(Y~., data_test)[,-1]
lasso_pred <- predict(lasso, s = best_lambda_lasso, newx = testX)
```

RMSE 값 계산
```{r}
RMSE(lasso_pred, data_test$Y)
```

마지막으로 traing set과 test set을 모두 포함하는 전체 dataset을 대상으로 best 값을 가지는 lasso regression 최종 model을 만든다.

```{r}
fullX <- model.matrix(Y~., data)[,-1]
fullY <- data$Y
lasso_full <- glmnet(x = fullX, y = fullY, alpha = 1)
predict(lasso_full, s = best_lambda_lasso, type = "coefficients")
```


2) caret package를 사용하여 repeated CV 실행

```{r, warning = FALSE}
set.seed(2020)
lasso_model <- train(Y~., data = data_train, method = "glmnet", tuneGrid = data.frame(alpha = 1, lambda = seq(0,14,length = 14)), trControl = trainControl(method = "repeatedcv", number = 10, repeats = 10))
lasso_model
```
```{r}
ggplot(lasso_model) + theme_bw()
lasso_model$bestTune
lasso_pred <- predict(lasso_model, data_test)
RMSE(lasso_pred, data_test$Y)
```


```{r}
coef(lasso_model$finalModel, lasso_model$bestTune$lambda)
```

Lasso Regression 수행 결과, best lambda 값은 1.076923, 이때의 cross validated RMSE 값은 4.599841이었다.
coefficient 값은 위와 같이 계산되었다. 이 모델에 X1, X2, X3 값을 포함시켰으며, 이는 실제 회귀식과 동일한 feature들이다.

필요 없는 변수들을 모두 0으로 제외시킨다는 점에서 Lasso Regression은 Ridge Regression보다 해석 능력에서 앞선다. Lasso는 계수를 0으로 만들어 제외시키면서, feature selection에서 탁월한 효과를 가지게 되는 것이다. 이 case와 같이 유의미한 변수가 적을때는 Lasso Regression을 사용하는 것이 Ridge보다 성능도 더 높다.

